# RA_5_2 - Instalaci√≥n de K3s en modo High Availability (HA) y despliegue de Nginx

## Introducci√≥n

En esta tarea se realiza la instalaci√≥n y configuraci√≥n de un cl√∫ster **K3s en modo HA (High Availability)**, utilizando m√∫ltiples nodos para garantizar la tolerancia a fallos y la alta disponibilidad del sistema. Posteriormente, se desplegar√° un servicio Nginx con 2 r√©plicas y se utilizar√° **K9s** para validar y gestionar el estado del cl√∫ster y los recursos.

## Requisitos Previos

Para poder llevar a cabo esta actividad, se requiere:

- Al menos **3 m√°quinas virtuales o f√≠sicas**.
- Sistema operativo Linux en todos los nodos.
- Acceso `sudo` en cada m√°quina
- Conexi√≥n de red entre los nodos
- Herramientas instaladas:
  - `curl`
  - `kubectl`
  - `k9s`
  - `openssh` habilitado entre nodos
- Los 3 equipos en este caso:
  - Equipo 1: Ubuntu Desktop 20.04 con ip '192.168.1.131' 
  - Equipo 2: Ubuntu Server con ip '192.168.1.134'
  - Equipo 3: Ubuntu Server con ip '192.168.1.135'

## üõ†Ô∏è Pasos para la instalaci√≥n y despliegue.

### Configurar los nodos

En todos los nodos deberemos actualizar el sistema:
```bash
sudo apt update && sudo apt upgrade -y
```

### Instalar K3s en modo HA en el nodo principal (Ubuntu Desktop 20.04).
Este nodo inicia el cl√∫ster con etcd embebido.
```bash
curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="server --cluster-init" sh -
```
![captura](images/Captura10.PNG)

A continuaci√≥n, obtendremos el token, necesario para la configuraci√≥n en el resto de nodos.
```bash
sudo cat /var/lib/rancher/k3s/server/node-token
```
![captura](images/Captura11.PNG)

# A√±adir el resto de nodos al plano de control.

### En los dem√°s nodos ejecutaremos:

![captura](images/Captura12.PNG) ![captura](images/Captura13.PNG)

## Verificar estado del cl√∫ster

En el nodo principal:
```bash
sudo kubectl get nodes
```
![captura](images/Captura14.PNG)

## Desplegar servicio NGINX 

### Ejecutar en el nodo principal: 
```bash
kubectl create deployment nginx --image=nginx
kubectl scale deployment nginx --replicas=2
kubectl expose deployment nginx --port=80 --type=NodePort
```
![captura](images/Captura15.PNG)

### Verificamos el estado:
```bash
sudo kubectl get pods -o wide
sudo kubectl get svc
```
![captura](images/Captura16.PNG)

### K9s y su ejecuci√≥n:
Al acceder a K9s tras haber instalado el cl√∫ster K3s en modo High Availability (HA) y desplegado el servicio Nginx, podremos observar un entorno distribuido y m√°s robusto. En la interfaz principal de K9s, se observan los nodos registrados en el cl√∫ster, todos en estado Ready, lo que indica que la configuraci√≥n HA ha sido exitosa y que el cl√∫ster reconoce correctamente todos los servidores y agentes.

Al inspeccionar los pods, podemos observar que las 2 r√©plicas de Nginx se encuentran en estado Running y distribuidas entre distintos nodos del cl√∫ster, lo que demuestra la capacidad de Kubernetes para balancear cargas y garantizar disponibilidad incluso si uno de los nodos falla.
![captura](images/Captura17.PNG)

## ‚úÖ Conclusi√≥n
En esta segunda tarea se ha conseguido desplegar un cl√∫ster K3s en modo High Availability (HA), demostrando c√≥mo se puede lograr un entorno de Kubernetes resiliente y distribuido con m√∫ltiples nodos. La correcta configuraci√≥n y sincronizaci√≥n entre los servidores y agentes han permitido establecer un cl√∫ster capaz de tolerar fallos y mantener la continuidad del servicio.

El despliegue del servicio Nginx con 2 r√©plicas ha servido como prueba funcional para validar la operaci√≥n del cl√∫ster, mostrando c√≥mo Kubernetes distribuye las cargas entre nodos y garantiza que las aplicaciones sigan disponibles incluso si un nodo deja de estar operativo.
